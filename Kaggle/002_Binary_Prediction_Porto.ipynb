{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguro’s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/porto-seguro-safe-driver-prediction\n",
    "\n",
    "In this competition, You challenged to build a model that predict the probability the driver will initiate an auto insurance claim in next year. While Porto Seguro has used machine learning for the post 20 years, they are looking for kaggle machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.\n",
    "\n",
    "> 이 대회에서 당신은 운전자가 내년에 자동차 보험 청구를 시작할 가능성을 예측하는 모델을 만드는 것에 도전했다. 포르토 세구로가 20년 동안 기계 학습을 사용했지만, 그들은 새롭고 더 강력한 방법을 탐구하기 위해 카글 기계 학습 커뮤니티를 찾고 있다. 좀 더 정확한 예측은 그들이 가격을 더 조정할 수 있게 해 줄 것이고, 희망컨대 더 많은 운전자들이 자동차 보험 혜택을 받을 수 있게 해줄 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook aims at getting a good insight in the data for the PortoSeguro competition. Besides that, it gives some tips and tips and tricks to prepare your data for modeling. The notebook consists of the following main sections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Visual inspect of your data](#visual_inspection)\n",
    "1. [Defining the metadata](#metadata)\n",
    "1. [Descriptive statistics](#descriptive_stats)\n",
    "1. [Handling imbalanced classes](#imbalance_data)\n",
    "1. [Data quality checks](#data_quality)\n",
    "1. [Exploratory Data visualization](#eda)\n",
    "1. [Feature engineering](#feat_engineering)\n",
    "1. [Feature selection](#feat_selection)\n",
    "1. [Feature scaling](#feat_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"visual_inspection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Visual inspect of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../input/porto/train.csv')\n",
    "test = pd.read_csv('../../input/porto/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. Data at first sight\n",
    "\n",
    "Here is an excerpt of the data description for competition:\n",
    "\n",
    "- Features that belong to **similar groupings are tagged** as such in the feature names (e.g., ind, reg, car, calc)\n",
    "- Feature names include the post-fix **bin** to indicate binary features and **cat** to indicate categorical features.\n",
    "- Features **without these designations are either continuous or ordinal.**\n",
    "- Values of **-1** indicate that the feature was **missing** from the observation.\n",
    "- The **Target** columns signifies whether or not a claim was filed for that policy holder.\n",
    "\n",
    "Ok, that's important information to get us started. Let's have a quick look at the first and last rows to confirm all of this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "0              0              0              1              0              0   \n",
       "1              0              0              0              1              0   \n",
       "\n",
       "   ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  ps_ind_13_bin  ps_ind_14  \\\n",
       "0              0              0              0              0          0   \n",
       "1              0              0              0              0          0   \n",
       "\n",
       "   ps_ind_15  ps_ind_16_bin  ps_ind_17_bin  ps_ind_18_bin  ps_reg_01  \\\n",
       "0         11              0              1              0        0.7   \n",
       "1          3              0              0              1        0.8   \n",
       "\n",
       "   ps_reg_02  ps_reg_03  ps_car_01_cat  ps_car_02_cat  ps_car_03_cat  \\\n",
       "0        0.2   0.718070             10              1             -1   \n",
       "1        0.4   0.766078             11              1             -1   \n",
       "\n",
       "   ps_car_04_cat  ps_car_05_cat  ps_car_06_cat  ps_car_07_cat  ps_car_08_cat  \\\n",
       "0              0              1              4              1              0   \n",
       "1              0             -1             11              1              1   \n",
       "\n",
       "   ps_car_09_cat  ps_car_10_cat  ps_car_11_cat  ps_car_11  ps_car_12  \\\n",
       "0              0              1             12          2   0.400000   \n",
       "1              2              1             19          3   0.316228   \n",
       "\n",
       "   ps_car_13  ps_car_14  ps_car_15  ps_calc_01  ps_calc_02  ps_calc_03  \\\n",
       "0   0.883679   0.370810   3.605551         0.6         0.5         0.2   \n",
       "1   0.618817   0.388716   2.449490         0.3         0.1         0.3   \n",
       "\n",
       "   ps_calc_04  ps_calc_05  ps_calc_06  ps_calc_07  ps_calc_08  ps_calc_09  \\\n",
       "0           3           1          10           1          10           1   \n",
       "1           2           1           9           5           8           1   \n",
       "\n",
       "   ps_calc_10  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           5           9           1           5           8               0   \n",
       "1           7           3           1           1           9               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>1488021</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.698212</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.764434</td>\n",
       "      <td>0.384968</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>1488027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.932649</td>\n",
       "      <td>0.378021</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "595210  1488021       0          5              2          3              1   \n",
       "595211  1488027       0          0              1          8              0   \n",
       "\n",
       "        ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "595210              0              0              0              1   \n",
       "595211              0              1              0              0   \n",
       "\n",
       "        ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  \\\n",
       "595210              0              0              0              0   \n",
       "595211              0              0              0              0   \n",
       "\n",
       "        ps_ind_13_bin  ps_ind_14  ps_ind_15  ps_ind_16_bin  ps_ind_17_bin  \\\n",
       "595210              0          0         12              1              0   \n",
       "595211              0          0          7              1              0   \n",
       "\n",
       "        ps_ind_18_bin  ps_reg_01  ps_reg_02  ps_reg_03  ps_car_01_cat  \\\n",
       "595210              0        0.9        0.4   0.698212             11   \n",
       "595211              0        0.1        0.2  -1.000000              7   \n",
       "\n",
       "        ps_car_02_cat  ps_car_03_cat  ps_car_04_cat  ps_car_05_cat  \\\n",
       "595210              1             -1              0             -1   \n",
       "595211              0             -1              0             -1   \n",
       "\n",
       "        ps_car_06_cat  ps_car_07_cat  ps_car_08_cat  ps_car_09_cat  \\\n",
       "595210             11              1              1              2   \n",
       "595211              0              1              0              2   \n",
       "\n",
       "        ps_car_10_cat  ps_car_11_cat  ps_car_11  ps_car_12  ps_car_13  \\\n",
       "595210              1            101          3   0.374166   0.764434   \n",
       "595211              1             34          2   0.400000   0.932649   \n",
       "\n",
       "        ps_car_14  ps_car_15  ps_calc_01  ps_calc_02  ps_calc_03  ps_calc_04  \\\n",
       "595210   0.384968   3.162278         0.0         0.7         0.0           4   \n",
       "595211   0.378021   3.741657         0.4         0.0         0.5           2   \n",
       "\n",
       "        ps_calc_05  ps_calc_06  ps_calc_07  ps_calc_08  ps_calc_09  \\\n",
       "595210           0           9           4           9           2   \n",
       "595211           3          10           4          10           2   \n",
       "\n",
       "        ps_calc_10  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  \\\n",
       "595210          11           4           1           4           2   \n",
       "595211           5           4           4           3           8   \n",
       "\n",
       "        ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "595210               0               1               1               1   \n",
       "595211               0               1               0               0   \n",
       "\n",
       "        ps_calc_19_bin  ps_calc_20_bin  \n",
       "595210               0               0  \n",
       "595211               0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We indeed see the following\n",
    "- binary variables\n",
    "- categorical variables of which the category values are integers\n",
    "- other variables with integer or float values\n",
    "- variables with -1 representing missing values\n",
    "- the target variable and an ID variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the number of rows and columns in the train data.\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 59 variables and 592,212 rows. Lets's see if we have the same number of variables in the test data. Let's see if there are duplicate rows the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No Duplicate rows, so that;s fine.\n",
    "train.drop_duplicates()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 58)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're missing one variable in the test set, but this is the target variables. So that's fine.\n",
    "Let's now investigate how many variables of each type we have.\n",
    "\n",
    "So later on we can create dummy variables for the 14 categorical variables. The *bin* variables are already binary and do not need dummification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595212 entries, 0 to 595211\n",
      "Data columns (total 59 columns):\n",
      "id                595212 non-null int64\n",
      "target            595212 non-null int64\n",
      "ps_ind_01         595212 non-null int64\n",
      "ps_ind_02_cat     595212 non-null int64\n",
      "ps_ind_03         595212 non-null int64\n",
      "ps_ind_04_cat     595212 non-null int64\n",
      "ps_ind_05_cat     595212 non-null int64\n",
      "ps_ind_06_bin     595212 non-null int64\n",
      "ps_ind_07_bin     595212 non-null int64\n",
      "ps_ind_08_bin     595212 non-null int64\n",
      "ps_ind_09_bin     595212 non-null int64\n",
      "ps_ind_10_bin     595212 non-null int64\n",
      "ps_ind_11_bin     595212 non-null int64\n",
      "ps_ind_12_bin     595212 non-null int64\n",
      "ps_ind_13_bin     595212 non-null int64\n",
      "ps_ind_14         595212 non-null int64\n",
      "ps_ind_15         595212 non-null int64\n",
      "ps_ind_16_bin     595212 non-null int64\n",
      "ps_ind_17_bin     595212 non-null int64\n",
      "ps_ind_18_bin     595212 non-null int64\n",
      "ps_reg_01         595212 non-null float64\n",
      "ps_reg_02         595212 non-null float64\n",
      "ps_reg_03         595212 non-null float64\n",
      "ps_car_01_cat     595212 non-null int64\n",
      "ps_car_02_cat     595212 non-null int64\n",
      "ps_car_03_cat     595212 non-null int64\n",
      "ps_car_04_cat     595212 non-null int64\n",
      "ps_car_05_cat     595212 non-null int64\n",
      "ps_car_06_cat     595212 non-null int64\n",
      "ps_car_07_cat     595212 non-null int64\n",
      "ps_car_08_cat     595212 non-null int64\n",
      "ps_car_09_cat     595212 non-null int64\n",
      "ps_car_10_cat     595212 non-null int64\n",
      "ps_car_11_cat     595212 non-null int64\n",
      "ps_car_11         595212 non-null int64\n",
      "ps_car_12         595212 non-null float64\n",
      "ps_car_13         595212 non-null float64\n",
      "ps_car_14         595212 non-null float64\n",
      "ps_car_15         595212 non-null float64\n",
      "ps_calc_01        595212 non-null float64\n",
      "ps_calc_02        595212 non-null float64\n",
      "ps_calc_03        595212 non-null float64\n",
      "ps_calc_04        595212 non-null int64\n",
      "ps_calc_05        595212 non-null int64\n",
      "ps_calc_06        595212 non-null int64\n",
      "ps_calc_07        595212 non-null int64\n",
      "ps_calc_08        595212 non-null int64\n",
      "ps_calc_09        595212 non-null int64\n",
      "ps_calc_10        595212 non-null int64\n",
      "ps_calc_11        595212 non-null int64\n",
      "ps_calc_12        595212 non-null int64\n",
      "ps_calc_13        595212 non-null int64\n",
      "ps_calc_14        595212 non-null int64\n",
      "ps_calc_15_bin    595212 non-null int64\n",
      "ps_calc_16_bin    595212 non-null int64\n",
      "ps_calc_17_bin    595212 non-null int64\n",
      "ps_calc_18_bin    595212 non-null int64\n",
      "ps_calc_19_bin    595212 non-null int64\n",
      "ps_calc_20_bin    595212 non-null int64\n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 267.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, with the info() method we see that the the data type is integer or float. No null values are present in the data set. That's normal because missing values are replaced by -1. We'll look into that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metadata\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. Metadata\n",
    "\n",
    "To facilitate the data management, we'll store meta-information about the variables in a DataFrame. This is helpful when we want to select specific variables for analysis, visualization, modeling, ....\n",
    "\n",
    "Concretely we will store:\n",
    "- **role** : input, ID, target\n",
    "- **level** : normal, interval, ordinal, binary\n",
    "- **keep** : True or False\n",
    "- **dtype** : int, float, str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for f in train.columns:\n",
    "    # Defining the role\n",
    "    if f == 'target':\n",
    "        role = 'target'\n",
    "    elif f == 'id':\n",
    "        role = 'id'\n",
    "    else:\n",
    "        role = 'input'\n",
    "    \n",
    "    # Defining the level\n",
    "    if 'bin' in f or f == 'target':\n",
    "        level = 'binary'\n",
    "    elif 'cat' in f or f == 'id':\n",
    "        level = 'normal'\n",
    "    elif train[f].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[f].dtype == int:\n",
    "        level = 'ordinal'\n",
    "    \n",
    "    # Initialize keep to True for all variables except for id\n",
    "    keep = True\n",
    "    if f == 'id':\n",
    "        keep = False\n",
    "    \n",
    "    # Defining the data type\n",
    "    dtype = train[f].dtype\n",
    "    \n",
    "    # Creating a Dict that contains all the metadata for the variable\n",
    "    f_dict={\n",
    "        'varname':f,\n",
    "        'role':role,\n",
    "        'level':level,\n",
    "        'keep':keep,\n",
    "        'dtype':dtype\n",
    "    }\n",
    "    data.append(f_dict)\n",
    "\n",
    "meta = pd.DataFrame(data, columns='varname role level keep dtype'.split())\n",
    "meta.set_index('varname', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>keep</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>varname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>id</td>\n",
       "      <td>normal</td>\n",
       "      <td>False</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>target</td>\n",
       "      <td>binary</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_01</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>input</td>\n",
       "      <td>normal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>True</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 role    level   keep  dtype\n",
       "varname                                     \n",
       "id                 id   normal  False  int64\n",
       "target         target   binary   True  int64\n",
       "ps_ind_01       input  ordinal   True  int64\n",
       "ps_ind_02_cat   input   normal   True  int64\n",
       "ps_ind_03       input  ordinal   True  int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show metadata Dataframe.\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object', name='varname')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example to extract all nominal variables that are not dropped.\n",
    "meta[(meta.level=='nominal')&(meta.keep)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>level</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input</td>\n",
       "      <td>binary</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input</td>\n",
       "      <td>interval</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input</td>\n",
       "      <td>normal</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input</td>\n",
       "      <td>ordinal</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>target</td>\n",
       "      <td>binary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     role     level  count\n",
       "0      id    normal      1\n",
       "1   input    binary     17\n",
       "2   input  interval     10\n",
       "3   input    normal     14\n",
       "4   input   ordinal     16\n",
       "5  target    binary      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below the number of variables per role and level are displayed.\n",
    "pd.DataFrame({'count':meta.groupby(['role','level'])['role'].size()}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='descriptive_stats'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descriptive statistics\n",
    "\n",
    "We can also apply the describe method no the dataframe. However, it doesn't make much sense to calculate the mean, std, ... on categorical variables and the id variable. We'll explore the categorical variables visually later.\n",
    "\n",
    "Thanks to our meta file we can easily select the variables on which we want to compute the descriptive statistics. To keep things clear, we'll do this per data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. Interval variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.610991</td>\n",
       "      <td>0.439184</td>\n",
       "      <td>0.551102</td>\n",
       "      <td>0.379945</td>\n",
       "      <td>0.813265</td>\n",
       "      <td>0.276256</td>\n",
       "      <td>3.065899</td>\n",
       "      <td>0.449756</td>\n",
       "      <td>0.449589</td>\n",
       "      <td>0.449849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.287643</td>\n",
       "      <td>0.404264</td>\n",
       "      <td>0.793506</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.224588</td>\n",
       "      <td>0.357154</td>\n",
       "      <td>0.731366</td>\n",
       "      <td>0.287198</td>\n",
       "      <td>0.286893</td>\n",
       "      <td>0.287153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.250619</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.670867</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>2.828427</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.720677</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.765811</td>\n",
       "      <td>0.368782</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.906190</td>\n",
       "      <td>0.396485</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.037945</td>\n",
       "      <td>1.264911</td>\n",
       "      <td>3.720626</td>\n",
       "      <td>0.636396</td>\n",
       "      <td>3.741657</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_reg_01      ps_reg_02      ps_reg_03      ps_car_12  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.610991       0.439184       0.551102       0.379945   \n",
       "std         0.287643       0.404264       0.793506       0.058327   \n",
       "min         0.000000       0.000000      -1.000000      -1.000000   \n",
       "25%         0.400000       0.200000       0.525000       0.316228   \n",
       "50%         0.700000       0.300000       0.720677       0.374166   \n",
       "75%         0.900000       0.600000       1.000000       0.400000   \n",
       "max         0.900000       1.800000       4.037945       1.264911   \n",
       "\n",
       "           ps_car_13      ps_car_14      ps_car_15     ps_calc_01  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.813265       0.276256       3.065899       0.449756   \n",
       "std         0.224588       0.357154       0.731366       0.287198   \n",
       "min         0.250619      -1.000000       0.000000       0.000000   \n",
       "25%         0.670867       0.333167       2.828427       0.200000   \n",
       "50%         0.765811       0.368782       3.316625       0.500000   \n",
       "75%         0.906190       0.396485       3.605551       0.700000   \n",
       "max         3.720626       0.636396       3.741657       0.900000   \n",
       "\n",
       "          ps_calc_02     ps_calc_03  \n",
       "count  595212.000000  595212.000000  \n",
       "mean        0.449589       0.449849  \n",
       "std         0.286893       0.287153  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.200000       0.200000  \n",
       "50%         0.400000       0.500000  \n",
       "75%         0.700000       0.700000  \n",
       "max         0.900000       0.900000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = meta[(meta.level=='interval')&(meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reg variables\n",
    "- only ps_reg_03 has missing values\n",
    "- the range (min to max) differs between the variables. We could apply scaling (e.g. StandardScaler), but it depends on the classifier we will want to use.\n",
    "\n",
    "#### car variable\n",
    "- ps_car_12 and ps_car_15 have missing values\n",
    "- again, the range differs and we could apply scaling.\n",
    "\n",
    "#### calc variables\n",
    "- no missing values\n",
    "- this seems to be some kind of ratio as the maximum is 0.9\n",
    "- all three_calc variables have very similar distributions\n",
    "\n",
    "**Overall**, we can see that the range of the interval variables is rather small. Perhaps some transformation(e.g. log) is already applied in order to anonymize the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.900378</td>\n",
       "      <td>4.423318</td>\n",
       "      <td>0.012451</td>\n",
       "      <td>7.299922</td>\n",
       "      <td>2.346072</td>\n",
       "      <td>2.372081</td>\n",
       "      <td>1.885886</td>\n",
       "      <td>7.689445</td>\n",
       "      <td>3.005823</td>\n",
       "      <td>9.225904</td>\n",
       "      <td>2.339034</td>\n",
       "      <td>8.433590</td>\n",
       "      <td>5.441382</td>\n",
       "      <td>1.441918</td>\n",
       "      <td>2.872288</td>\n",
       "      <td>7.539026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.983789</td>\n",
       "      <td>2.699902</td>\n",
       "      <td>0.127545</td>\n",
       "      <td>3.546042</td>\n",
       "      <td>0.832548</td>\n",
       "      <td>1.117219</td>\n",
       "      <td>1.134927</td>\n",
       "      <td>1.334312</td>\n",
       "      <td>1.414564</td>\n",
       "      <td>1.459672</td>\n",
       "      <td>1.246949</td>\n",
       "      <td>2.904597</td>\n",
       "      <td>2.332871</td>\n",
       "      <td>1.202963</td>\n",
       "      <td>1.694887</td>\n",
       "      <td>2.746652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ps_ind_01      ps_ind_03      ps_ind_14      ps_ind_15  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        1.900378       4.423318       0.012451       7.299922   \n",
       "std         1.983789       2.699902       0.127545       3.546042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       2.000000       0.000000       5.000000   \n",
       "50%         1.000000       4.000000       0.000000       7.000000   \n",
       "75%         3.000000       6.000000       0.000000      10.000000   \n",
       "max         7.000000      11.000000       4.000000      13.000000   \n",
       "\n",
       "           ps_car_11     ps_calc_04     ps_calc_05     ps_calc_06  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        2.346072       2.372081       1.885886       7.689445   \n",
       "std         0.832548       1.117219       1.134927       1.334312   \n",
       "min        -1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       2.000000       1.000000       7.000000   \n",
       "50%         3.000000       2.000000       2.000000       8.000000   \n",
       "75%         3.000000       3.000000       3.000000       9.000000   \n",
       "max         3.000000       5.000000       6.000000      10.000000   \n",
       "\n",
       "          ps_calc_07     ps_calc_08     ps_calc_09     ps_calc_10  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        3.005823       9.225904       2.339034       8.433590   \n",
       "std         1.414564       1.459672       1.246949       2.904597   \n",
       "min         0.000000       2.000000       0.000000       0.000000   \n",
       "25%         2.000000       8.000000       1.000000       6.000000   \n",
       "50%         3.000000       9.000000       2.000000       8.000000   \n",
       "75%         4.000000      10.000000       3.000000      10.000000   \n",
       "max         9.000000      12.000000       7.000000      25.000000   \n",
       "\n",
       "          ps_calc_11     ps_calc_12     ps_calc_13     ps_calc_14  \n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000  \n",
       "mean        5.441382       1.441918       2.872288       7.539026  \n",
       "std         2.332871       1.202963       1.694887       2.746652  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         4.000000       1.000000       2.000000       6.000000  \n",
       "50%         5.000000       1.000000       3.000000       7.000000  \n",
       "75%         7.000000       2.000000       4.000000       9.000000  \n",
       "max        19.000000      10.000000      13.000000      23.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = meta[(meta.level=='ordinal')&(meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only one missing variable: ps_car_11\n",
    "- We could apply scaling to deal with the different ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.036448</td>\n",
       "      <td>0.393742</td>\n",
       "      <td>0.257033</td>\n",
       "      <td>0.163921</td>\n",
       "      <td>0.185304</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.660823</td>\n",
       "      <td>0.121081</td>\n",
       "      <td>0.153446</td>\n",
       "      <td>0.122427</td>\n",
       "      <td>0.627840</td>\n",
       "      <td>0.554182</td>\n",
       "      <td>0.287182</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.153318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187401</td>\n",
       "      <td>0.488579</td>\n",
       "      <td>0.436998</td>\n",
       "      <td>0.370205</td>\n",
       "      <td>0.388544</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.096693</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.473430</td>\n",
       "      <td>0.326222</td>\n",
       "      <td>0.360417</td>\n",
       "      <td>0.327779</td>\n",
       "      <td>0.483381</td>\n",
       "      <td>0.497056</td>\n",
       "      <td>0.452447</td>\n",
       "      <td>0.476662</td>\n",
       "      <td>0.360295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              target  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.036448       0.393742       0.257033       0.163921   \n",
       "std         0.187401       0.488579       0.436998       0.370205   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       1.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_09_bin  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.185304       0.000373       0.001692       0.009439   \n",
       "std         0.388544       0.019309       0.041097       0.096693   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_ind_13_bin  ps_ind_16_bin  ps_ind_17_bin  ps_ind_18_bin  \\\n",
       "count  595212.000000  595212.000000  595212.000000  595212.000000   \n",
       "mean        0.000948       0.660823       0.121081       0.153446   \n",
       "std         0.030768       0.473430       0.326222       0.360417   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       1.000000       0.000000       0.000000   \n",
       "75%         0.000000       1.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n",
       "count   595212.000000   595212.000000   595212.000000   595212.000000   \n",
       "mean         0.122427        0.627840        0.554182        0.287182   \n",
       "std          0.327779        0.483381        0.497056        0.452447   \n",
       "min          0.000000        0.000000        0.000000        0.000000   \n",
       "25%          0.000000        0.000000        0.000000        0.000000   \n",
       "50%          0.000000        1.000000        1.000000        0.000000   \n",
       "75%          0.000000        1.000000        1.000000        1.000000   \n",
       "max          1.000000        1.000000        1.000000        1.000000   \n",
       "\n",
       "       ps_calc_19_bin  ps_calc_20_bin  \n",
       "count   595212.000000   595212.000000  \n",
       "mean         0.349024        0.153318  \n",
       "std          0.476662        0.360295  \n",
       "min          0.000000        0.000000  \n",
       "25%          0.000000        0.000000  \n",
       "50%          0.000000        0.000000  \n",
       "75%          1.000000        0.000000  \n",
       "max          1.000000        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = meta[(meta.level=='binary')&(meta.keep)].index\n",
    "train[v].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A priori in the train data is 3.645%, which is **strongly imbalanced**.\n",
    "- From the means we can conclude that for most variables is zero in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Handling imbalanced classes\n",
    "\n",
    "As we mentioned above the proportion of records with target=1 is far less than target=0. This can lead to a model that has great accuracy but does have any added value in practice. Two possible to deal with this problem are:\n",
    "\n",
    "- oversampling records with target=1\n",
    "- undersampling records with target=0\n",
    "\n",
    "There are many more strategies of course and MachineLerningMastery.com gives a [nice overview]((https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/). AS we have a rather large training set, we can go for **undersampling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_apriori=0.10\n",
    "\n",
    "# Get the indices per targetr value\n",
    "idx_0 = train[train.target == 0].index\n",
    "idx_1 = train[train.target == 1].index\n",
    "\n",
    "# Get original number of records per target value\n",
    "nb_0 = len(train.loc[idx_0])\n",
    "nb_1 = len(train.loc[idx_1])\n",
    "\n",
    "# Calculate the undersmpling rate and resulting number of records with target=0\n",
    "undersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\n",
    "undersampling_nb_0 = int(undersampling_rate*nb_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,     10,\n",
       "            ...\n",
       "            595202, 595203, 595204, 595205, 595206, 595207, 595208, 595209,\n",
       "            595210, 595211],\n",
       "           dtype='int64', length=573518)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f226ac92-3d30-41ce-ba53-2a2813159843",
    "_uuid": "02cad71ec7e2a7370ec81655f6320bb88ce43a1e"
   },
   "source": [
    "<a class=\"anchor\" id=\"imbalanced_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e933f241-74eb-46ed-a7a8-02215f170db5",
    "_uuid": "4078855ef511dbbb2306f861e4b82ad45620e36f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desired_apriori=0.10\n",
    "\n",
    "# Get the indices per target value\n",
    "idx_0 = train[train.target == 0].index\n",
    "idx_1 = train[train.target == 1].index\n",
    "\n",
    "# Get original number of records per target value\n",
    "nb_0 = len(train.loc[idx_0])\n",
    "nb_1 = len(train.loc[idx_1])\n",
    "\n",
    "# Calculate the undersampling rate and resulting number of records with target=0\n",
    "undersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\n",
    "undersampled_nb_0 = int(undersampling_rate*nb_0)\n",
    "print('Rate to undersample records with target=0: {}'.format(undersampling_rate))\n",
    "print('Number of records with target=0 after undersampling: {}'.format(undersampled_nb_0))\n",
    "\n",
    "# Randomly select records with target=0 to get at the desired a priori\n",
    "undersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0)\n",
    "\n",
    "# Construct list with remaining indices\n",
    "idx_list = list(undersampled_idx) + list(idx_1)\n",
    "\n",
    "# Return undersample data frame\n",
    "train = train.loc[idx_list].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "209074dd-ee1f-465c-8cd7-d0b7b692f54f",
    "_uuid": "f48e8ee8ed611da6c42de9c595fdaf34ecf5f23b"
   },
   "source": [
    "<a class=\"anchor\" id=\"data_quality\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a1a31824-fa60-4140-ab09-72582a6ea446",
    "_uuid": "a0fc1970db23b67afabe087dd724764f4eef62cf"
   },
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19c7aeed-e009-43fb-a462-4a39707b3b86",
    "_uuid": "9304c0f92541692305b9fe77705d55a8ffb7d11a"
   },
   "source": [
    "### Checking missing values\n",
    "Missings are represented as -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46adfb57-916f-4cf8-87ae-f03ad861e621",
    "_uuid": "2d4770d2d4b49b2a0b62d84f3e4d57382d36f2cf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vars_with_missing = []\n",
    "\n",
    "for f in train.columns:\n",
    "    missings = train[train[f] == -1][f].count()\n",
    "    if missings > 0:\n",
    "        vars_with_missing.append(f)\n",
    "        missings_perc = missings/train.shape[0]\n",
    "        \n",
    "        print('Variable {} has {} records ({:.2%}) with missing values'.format(f, missings, missings_perc))\n",
    "        \n",
    "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88daeb5b-9dbf-4e15-af12-e952aac4b874",
    "_uuid": "869694ad63ab68d25588768879d26b49d7624d09"
   },
   "source": [
    "- **ps_car_03_cat and ps_car_05_cat** have a large proportion of  records with missing values. Remove these variables.\n",
    "- For the other categorical variables with missing values, we can leave the missing value -1 as such.\n",
    "- **ps_reg_03** (continuous) has missing values for 18% of all records. Replace by the mean.\n",
    "- **ps_car_11** (ordinal) has only 5 records with misisng values. Replace by the mode.\n",
    "- **ps_car_12** (continuous) has only 1 records with missing value. Replace by the mean.\n",
    "- **ps_car_14** (continuous) has missing values for 7% of all records. Replace by the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "183be251-710e-408f-b72e-1e5f40d1890c",
    "_uuid": "9cbd1e802e35b7d3e21ed696084d12d777210b3f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping the variables with too many missing values\n",
    "vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "train.drop(vars_to_drop, inplace=True, axis=1)\n",
    "meta.loc[(vars_to_drop),'keep'] = False  # Updating the meta\n",
    "\n",
    "# Imputing with the mean or mode\n",
    "mean_imp = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "mode_imp = Imputer(missing_values=-1, strategy='most_frequent', axis=0)\n",
    "train['ps_reg_03'] = mean_imp.fit_transform(train[['ps_reg_03']]).ravel()\n",
    "train['ps_car_12'] = mean_imp.fit_transform(train[['ps_car_12']]).ravel()\n",
    "train['ps_car_14'] = mean_imp.fit_transform(train[['ps_car_14']]).ravel()\n",
    "train['ps_car_11'] = mode_imp.fit_transform(train[['ps_car_11']]).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b137e94d-b57d-4761-830f-30d6a512fde2",
    "_uuid": "279507e3c1143e9d786edaa95e57f8ae42bed1cd"
   },
   "source": [
    "### Checking the cardinality of the categorical variables\n",
    "Cardinality refers to the number of different values in a variable. As we will create dummy variables from the categorical variables later on, we need to check whether there are variables with many distinct values. We should handle these variables differently as they would result in many dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55d5b4b2-f6f8-4c0d-9335-10c0e8d9e91e",
    "_uuid": "1cd88947790cf6422806529e62c9751dcbf0db89",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    dist_values = train[f].value_counts().shape[0]\n",
    "    print('Variable {} has {} distinct values'.format(f, dist_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8662f47c-27b4-4f88-bccc-f229890ebc4d",
    "_uuid": "d7f83fa79ddf0d76857c5a3bdb909c271574eab3"
   },
   "source": [
    "Only **ps_car_11_cat** has many distinct values, although it is still reasonable. \n",
    "\n",
    "**EDIT:** [nickycan](https://www.kaggle.com/nickycan) made an excellent remark on the fact that my first solution could lead to data leakage. He also pointed me to another kernel made by [oliver](https://www.kaggle.com/ogrellier) which deals with that. I therefore replaced this part with the kernel of oliver. All credits go to him. It is so great what you can learn by participating in the Kaggle competitions :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "69f34b04db61f7fd9c9d3d9d926faedc7a8adf26",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script by https://www.kaggle.com/ogrellier\n",
    "# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  tst_series=None, \n",
    "                  target=None, \n",
    "                  min_samples_leaf=1, \n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior  \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b735e1a7a82fa8dfcd33518b76f4ab2271ceadfe",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_encoded, test_encoded = target_encode(train[\"ps_car_11_cat\"], \n",
    "                             test[\"ps_car_11_cat\"], \n",
    "                             target=train.target, \n",
    "                             min_samples_leaf=100,\n",
    "                             smoothing=10,\n",
    "                             noise_level=0.01)\n",
    "    \n",
    "train['ps_car_11_cat_te'] = train_encoded\n",
    "train.drop('ps_car_11_cat', axis=1, inplace=True)\n",
    "meta.loc['ps_car_11_cat','keep'] = False  # Updating the meta\n",
    "test['ps_car_11_cat_te'] = test_encoded\n",
    "test.drop('ps_car_11_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "555fdddf-e3c5-4c84-a017-d292eaab07ac",
    "_uuid": "e31feea1985ee709ccc37bc5c6dc31e8632c0070"
   },
   "source": [
    "<a class=\"anchor\" id=\"eda\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21e70f2e-84f2-422d-9962-b783ae4a4024",
    "_uuid": "d6f7d15dc7b90269ccf1fcdef0762e0352a3fe5b"
   },
   "source": [
    "## Exploratory Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b3c403c4-943a-45c2-a0ab-96e72c04fe6d",
    "_uuid": "e06225d3d3dde0380c7502471ab580ae883329c4"
   },
   "source": [
    "### Categorical variables\n",
    "Let's look into the categorical variables and the proportion of customers with target = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "65ae81d3-aec8-4936-ad4a-978fd3c15b2e",
    "_uuid": "d526aedf99612576de7d7e57c488d3f5d0fd2742",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "\n",
    "for f in v:\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    # Calculate the percentage of target=1 per category value\n",
    "    cat_perc = train[[f, 'target']].groupby([f],as_index=False).mean()\n",
    "    cat_perc.sort_values(by='target', ascending=False, inplace=True)\n",
    "    # Bar plot\n",
    "    # Order the bars descending on target mean\n",
    "    sns.barplot(ax=ax, x=f, y='target', data=cat_perc, order=cat_perc[f])\n",
    "    plt.ylabel('% target', fontsize=18)\n",
    "    plt.xlabel(f, fontsize=18)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "466bf1c0-fc53-40db-9f11-ae81b12b41fb",
    "_uuid": "c403f713d0adf7f294c6f8f439e94ad27ba99c74"
   },
   "source": [
    "As we can see from the variables **with missing values**,  it is a good idea to keep the missing values as a separate category value, instead of replacing them by the mode for instance. The customers with a missing value appear to have a much higher (in some cases much lower) probability to ask for an insurance claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "93facc26-1116-41a7-8bc3-a3de5cc1e0d9",
    "_uuid": "21e20154f1c847567ea99b7240305f6a3145368c"
   },
   "source": [
    "### Interval variables\n",
    "Checking the correlations between interval variables. A heatmap is a good way to visualize the correlation between variables. The code below is based on [an example by Michael Waskom](http://seaborn.pydata.org/examples/many_pairwise_correlations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e969c00b-b09c-49ac-9acd-c07796a944df",
    "_uuid": "c0037596fe7df705bdad63e4f61a06a08c4cccc3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr_heatmap(v):\n",
    "    correlations = train[v].corr()\n",
    "\n",
    "    # Create color map ranging between two colors\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f',\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .75})\n",
    "    plt.show();\n",
    "    \n",
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "corr_heatmap(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc2bb0c9-7b8b-4536-9f2a-5b1279475d19",
    "_uuid": "9dbe7c73bf99bd8526d4b2a3e95e18f0ce8734b4"
   },
   "source": [
    "There are a strong correlations between the variables:\n",
    "- ps_reg_02 and ps_reg_03 (0.7)\n",
    "- ps_car_12 and ps_car13 (0.67)\n",
    "- ps_car_12 and ps_car14 (0.58)\n",
    "- ps_car_13 and ps_car15 (0.67)\n",
    "\n",
    "Seaborn has some handy plots to visualize the (linear) relationship between variables. We could use a *pairplot* to visualize the relationship between the variables. But because the heatmap already showed the limited number of correlated variables, we'll look at each of the highly correlated variables separately.<br>\n",
    "**NOTE**: I take a sample of the train data to speed up the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd8e84fc-9a4b-4b2e-ae63-f0eec75ca5f1",
    "_uuid": "57003a9c9fb3371810d38077ccdfe0afbf1672b9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = train.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2a2a231d-ce98-41f5-8803-f12173bdefc0",
    "_uuid": "8ceb63bc7cea9e0437e29eaf6e7a2c7cb0526894"
   },
   "source": [
    "#### ps_reg_02 and ps_reg_03\n",
    "As the regression line shows, there is a linear relationship between these variables. Thanks to the *hue* parameter we can see that the regression lines for target=0 and target=1 are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3b9ade09-a679-44d3-b28c-2c152abf1876",
    "_uuid": "3f7c86df8ddcd0ea5ae47ca59d365ef8e928309b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='ps_reg_02', y='ps_reg_03', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd1ca3ee-c4bd-426d-88d2-d2f0e1b2e8c3",
    "_uuid": "0823b40bab165ced5c95f7409215b5c1fa626074"
   },
   "source": [
    "#### ps_car_12 and ps_car_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6dbb6e9-199f-498c-ae08-932a5150b613",
    "_uuid": "8869035a748b543e838c4710e1c7ad2d9add413e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='ps_car_12', y='ps_car_13', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4882daa7-11cd-4f15-b876-fc058e03174c",
    "_uuid": "9347a90f21d7d45f45329b2bbb3341ada1b41022"
   },
   "source": [
    "#### ps_car_12 and ps_car_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "78da0148-a6da-4b34-84c5-3ac7577c0b25",
    "_uuid": "12f93ff9edad366928c61540dd34055f55aff5ca",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='ps_car_12', y='ps_car_14', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff26f47b-bff7-4547-ac9b-5a6df8d4d071",
    "_uuid": "1a89b9a550afaa8c0984a7418ae834c63c683752"
   },
   "source": [
    "#### ps_car_13 and ps_car_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4b8cfd4a-cb8d-4c3e-b46b-6db77e158bac",
    "_uuid": "74f1216cbc52e181b7512cd9145ebb313d457cdf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='ps_car_15', y='ps_car_13', data=s, hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dec7b4dd-c93c-47e1-ab2d-548f432ce4a0",
    "_uuid": "60978caa946dae49052a52ec407b9a1fe3e17881"
   },
   "source": [
    "Allright, so now what? How can we decide which of the correlated variables to keep? We could perform Principal Component Analysis (PCA) on the variables to reduce the dimensions. In the AllState Claims Severity Competition I made [this kernel](https://www.kaggle.com/bertcarremans/reducing-number-of-numerical-features-with-pca) to do that. But as the number of correlated variables is rather low, we will let the model do the heavy-lifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9cbdbc6f-9ff4-4c28-9dba-b19e93bc9708",
    "_uuid": "d1fcda209f3dfc9cae005cdee9aafcb26b9e6475"
   },
   "source": [
    "### Checking the correlations between ordinal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8fb69015-aecb-4cb0-a803-1f304bd9d262",
    "_uuid": "2c64593f289400b81ded88b2159e656786445981",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'ordinal') & (meta.keep)].index\n",
    "corr_heatmap(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2374e64-1327-475c-b375-8b6e73717864",
    "_uuid": "3bf34ff124004015f2176ecb42d469bcb22f048f"
   },
   "source": [
    "For the ordinal variables we do not see many correlations. We could, on the other hand, look at how the distributions are when grouping by the target value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e92bc0e5-268c-4d8b-818b-0309dfa18eae",
    "_uuid": "c8be9e3000a2860cd78ac36633f850d366d6f9d8"
   },
   "source": [
    "<a class=\"anchor\" id=\"feat_engineering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "40ef3784-1878-4e25-9854-b43746f63bf8",
    "_uuid": "1a68029b3e8b713d966d4ad931568726b0df75a0"
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5137cbb-6779-4aad-898c-19a5ba815a9c",
    "_uuid": "a617be4ecc6c94a2a6fde837377b4915b3f372a0"
   },
   "source": [
    "### Creating dummy variables\n",
    "The values of the categorical variables do not represent any order or magnitude. For instance, category 2 is not twice the value of category 1. Therefore we can create dummy variables to deal with that. We drop the first dummy variable as this information can be derived from the other dummy variables generated for the categories of the original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6606cf2b-9082-4d5e-b278-2779780258a6",
    "_uuid": "12554d624df68deff6fd0e9c5f90a61c1e1c83c0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'nominal') & (meta.keep)].index\n",
    "print('Before dummification we have {} variables in train'.format(train.shape[1]))\n",
    "train = pd.get_dummies(train, columns=v, drop_first=True)\n",
    "print('After dummification we have {} variables in train'.format(train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "afa36be5-c104-4b7e-bf68-3a6a52cd36ce",
    "_uuid": "50174c5dd05a9fafbe4a12a604dbb7951235774f"
   },
   "source": [
    "So, creating dummy variables adds 52 variables to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "10ce6e10-d129-4596-b394-40f179627378",
    "_uuid": "1b62391ed9a0401d0e6bd6a0e5ab06cb5677b6f0"
   },
   "source": [
    "### Creating interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ff3bc120-fa06-44b5-9a3b-73b766a47b5f",
    "_uuid": "9dd8f8a47d5aaa03f24fa614aac9c295244ba416",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = meta[(meta.level == 'interval') & (meta.keep)].index\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
    "interactions = pd.DataFrame(data=poly.fit_transform(train[v]), columns=poly.get_feature_names(v))\n",
    "interactions.drop(v, axis=1, inplace=True)  # Remove the original columns\n",
    "# Concat the interaction variables to the train data\n",
    "print('Before creating interactions we have {} variables in train'.format(train.shape[1]))\n",
    "train = pd.concat([train, interactions], axis=1)\n",
    "print('After creating interactions we have {} variables in train'.format(train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd57b8d1-e14a-4242-b0b9-9afd1a132fe9",
    "_uuid": "02036e241b551d5f7bede25fc4f36de53150df6d"
   },
   "source": [
    "This adds extra interaction variables to the train data. Thanks to the *get_feature_names* method we can assign column names to these \n",
    "new variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb9265c9-771b-4ca7-a889-9b37b9eab6c0",
    "_uuid": "58b2f554c11134975e5d1d8ef3d77ea3fbbaa46f"
   },
   "source": [
    "<a class=\"anchor\" id=\"feat_selection\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f2abaa9f-7cdc-4384-80b5-e63597d8cec8",
    "_uuid": "9a5a578a079d355fa2beff6eb88c5d4d17e38add"
   },
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07f5f01b-578a-45ba-86ca-96f1427fec20",
    "_uuid": "b78df6efd06d4d89406f993e606c29a1428a882a"
   },
   "source": [
    "### Removing features with low or zero variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3c9e71d5-83e9-4dcb-ad59-4d0f8260266a",
    "_uuid": "1e40858bb47e2bf41c3cce72f40a03024b0a4f9f"
   },
   "source": [
    "Personally, I prefer to let the classifier algorithm chose which features to keep. But there is one thing that we can do ourselves. That is removing features with no or a very low variance. Sklearn has a handy method to do that: **VarianceThreshold**. By default it removes features with zero variance. This will not be applicable for this competition as we saw there are no zero-variance variables in the previous steps. But if we would remove features with less than 1% variance, we would remove 31 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "41a072b2-85f5-4bb9-afe7-3b5cf3ac51a6",
    "_uuid": "f7e68cb2653dc241b3f86539675632b13c63e211",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold=.01)\n",
    "selector.fit(train.drop(['id', 'target'], axis=1)) # Fit to train without id and target variables\n",
    "\n",
    "f = np.vectorize(lambda x : not x) # Function to toggle boolean array elements\n",
    "\n",
    "v = train.drop(['id', 'target'], axis=1).columns[f(selector.get_support())]\n",
    "print('{} variables have too low variance.'.format(len(v)))\n",
    "print('These variables are {}'.format(list(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6bcf15e1-e12b-4690-999a-a6b0287785a2",
    "_uuid": "5fb5fc6f9d8b477f6a2edc1850621f0f92f6d239"
   },
   "source": [
    "We would lose rather many variables if we would select based on variance. But because we do not have so many variables, we'll let the classifier chose. For data sets with many more variables this could reduce the processing time.\n",
    "\n",
    "Sklearn also comes with other [feature selection methods](http://scikit-learn.org/stable/modules/feature_selection.html). One of these methods is *SelectFromModel* in which you let another classifier select the best features and continue with these. Below I'll show you how to do that with a Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5f91639-6eb2-4d08-a90e-7893b9ae871a",
    "_uuid": "8f7aa5366fdbe5abc662b66044eee51ba7b9199b"
   },
   "source": [
    "### Selecting features with a Random Forest and SelectFromModel\n",
    "Here we'll base feature selection on the feature importances of a random forest. With Sklearn's SelectFromModel you can then specify how many variables you want to keep. You can set a threshold on the level of feature importance manually. But we'll simply select the top 50% best variables. \n",
    "\n",
    "> The code in the cell below is borrowed from the [GitHub repo of Sebastian Raschka](https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch04/ch04.ipynb). This repo contains code samples of his book *Python Machine Learning*, which is an absolute must to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68538296-829c-4b96-bd0a-f87e6551c09b",
    "_uuid": "f2acc04bcfb97bb32d420d09760b691b389ec131",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(['id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "feat_labels = X_train.columns\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "indices = np.argsort(rf.feature_importances_)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30,feat_labels[indices[f]], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9aa9b7d-2834-4d82-b300-d98704dcf4b2",
    "_uuid": "a4e25a206e24715c5c0ae55c32693d8fbefc3c8f"
   },
   "source": [
    "With SelectFromModel we can specify which prefit classifier to use and what the threshold is for the feature importances. With the *get_support* method we can then limit the number of variables in the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "17703fb7-c45b-48c4-b397-97b60fd7bd02",
    "_uuid": "8374d3bcb725a9331b57baf209279593fe82f7b0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfm = SelectFromModel(rf, threshold='median', prefit=True)\n",
    "print('Number of features before selection: {}'.format(X_train.shape[1]))\n",
    "n_features = sfm.transform(X_train).shape[1]\n",
    "print('Number of features after selection: {}'.format(n_features))\n",
    "selected_vars = list(feat_labels[sfm.get_support()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "608f476c-a707-4ae8-afda-d18766a237ec",
    "_uuid": "739729e399a58cef39570216b481486f6c9d4dac",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train[selected_vars + ['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "525b9c98-40bd-4115-b9a7-c0688940fad7",
    "_uuid": "bbe680ed6436dae96d6bbd1e10b5053ba6fe7f6d"
   },
   "source": [
    "<a class=\"anchor\" id=\"feat_scaling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ed8f51ef-a528-4dd7-9a9e-3fe6abae76cc",
    "_uuid": "2a3fd5dfb7a710eb74a590e978768675a21e5c34"
   },
   "source": [
    "## Feature scaling\n",
    "As mentioned before, we can apply standard scaling to the training data. Some classifiers perform better when this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9e461415-d087-43c6-96e8-021a61bb76b1",
    "_uuid": "df5e30846f84916d5bee758d035790e94b50e04d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(train.drop(['target'], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "de7a1f63-ccb4-49f0-bf3e-8e1181c5c5be",
    "_uuid": "b8aa7aee1c138ab00cecc0197b33d07d9a1cc1e0"
   },
   "source": [
    "## Conclusion\n",
    "Hopefully this notebook helped you with some tips on how to start with this competition. Feel free to vote for it. And if you have questions, post a comment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
